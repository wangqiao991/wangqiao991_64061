{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAEYst82CDPR",
    "tags": []
   },
   "source": [
    "## Using a pretrained network with training sample of 1000, a validation sample of 500, and a test sample of 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8wI8jDeCDPR",
    "tags": []
   },
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:25.649490Z",
     "iopub.status.busy": "2023-10-21T19:59:25.646353Z",
     "iopub.status.idle": "2023-10-21T19:59:25.650958Z",
     "shell.execute_reply": "2023-10-21T19:59:25.651965Z"
    },
    "id": "53GKP3NWCDPS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!unzip -qq '/fs/ess/PGS0333/BA_64061_KSU/data/dogs-vs-cats.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:25.658648Z",
     "iopub.status.busy": "2023-10-21T19:59:25.657456Z",
     "iopub.status.idle": "2023-10-21T19:59:25.661230Z",
     "shell.execute_reply": "2023-10-21T19:59:25.662175Z"
    },
    "id": "ZfGEQ2r_CDPT"
   },
   "outputs": [],
   "source": [
    "#!unzip -qq train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC5cZm4DCDPT",
    "tags": []
   },
   "source": [
    "**Copying images to training, validation, and test directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:25.687683Z",
     "iopub.status.busy": "2023-10-21T19:59:25.686563Z",
     "iopub.status.idle": "2023-10-21T19:59:45.006740Z",
     "shell.execute_reply": "2023-10-21T19:59:45.005038Z"
    },
    "id": "Z8dqOCnvCDPT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPybxeH3CDPT",
    "tags": []
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KE0mXcPvCDPU"
   },
   "source": [
    "**Instantiating a small convnet for dogs vs. cats classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:45.021734Z",
     "iopub.status.busy": "2023-10-21T19:59:45.020208Z",
     "iopub.status.idle": "2023-10-21T19:59:45.052968Z",
     "shell.execute_reply": "2023-10-21T19:59:45.054313Z"
    },
    "id": "TIDD8c0VCDPU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\ninputs = keras.Input(shape=(180, 180, 3))\\nx = layers.Rescaling(1./255)(inputs)\\nx = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\\nx = layers.Flatten()(x)\\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\\nmodel = keras.Model(inputs=inputs, outputs=outputs)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:45.061948Z",
     "iopub.status.busy": "2023-10-21T19:59:45.060269Z",
     "iopub.status.idle": "2023-10-21T19:59:45.065217Z",
     "shell.execute_reply": "2023-10-21T19:59:45.063892Z"
    },
    "id": "pcBTjksSCDPU"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKCFKNAVCDPV"
   },
   "source": [
    "**Configuring the model for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:45.073164Z",
     "iopub.status.busy": "2023-10-21T19:59:45.071648Z",
     "iopub.status.idle": "2023-10-21T19:59:45.076921Z",
     "shell.execute_reply": "2023-10-21T19:59:45.078017Z"
    },
    "id": "SXDcTiDKCDPV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(loss=\"binary_crossentropy\",\\n              optimizer=\"rmsprop\",\\n              metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyB79XdQCDPV"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuadPMYcCDPV"
   },
   "source": [
    "**Using `image_dataset_from_directory` to read images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T19:59:45.087252Z",
     "iopub.status.busy": "2023-10-21T19:59:45.086258Z",
     "iopub.status.idle": "2023-10-21T20:00:12.954441Z",
     "shell.execute_reply": "2023-10-21T20:00:12.955695Z"
    },
    "id": "-2sPJf98CDPW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:12.964805Z",
     "iopub.status.busy": "2023-10-21T20:00:12.963415Z",
     "iopub.status.idle": "2023-10-21T20:00:12.968993Z",
     "shell.execute_reply": "2023-10-21T20:00:12.970021Z"
    },
    "id": "xaOvG3kRCDPW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport tensorflow as tf\\nrandom_numbers = np.random.normal(size=(1000, 16))\\ndataset = tf.data.Dataset.from_tensor_slices(random_numbers)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "random_numbers = np.random.normal(size=(1000, 16))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:12.978155Z",
     "iopub.status.busy": "2023-10-21T20:00:12.976888Z",
     "iopub.status.idle": "2023-10-21T20:00:12.983038Z",
     "shell.execute_reply": "2023-10-21T20:00:12.981919Z"
    },
    "id": "VOJjVIR1CDPW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i, element in enumerate(dataset):\\n    print(element.shape)\\n    if i >= 2:\\n        break\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i, element in enumerate(dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:12.990487Z",
     "iopub.status.busy": "2023-10-21T20:00:12.989288Z",
     "iopub.status.idle": "2023-10-21T20:00:12.993892Z",
     "shell.execute_reply": "2023-10-21T20:00:12.994786Z"
    },
    "id": "GuRLcC71CDPe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatched_dataset = dataset.batch(32)\\nfor i, element in enumerate(batched_dataset):\\n    print(element.shape)\\n    if i >= 2:\\n        break\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "batched_dataset = dataset.batch(32)\n",
    "for i, element in enumerate(batched_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.001578Z",
     "iopub.status.busy": "2023-10-21T20:00:13.000550Z",
     "iopub.status.idle": "2023-10-21T20:00:13.004581Z",
     "shell.execute_reply": "2023-10-21T20:00:13.005340Z"
    },
    "id": "oQDZXyr8CDPf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nreshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\\nfor i, element in enumerate(reshaped_dataset):\\n    print(element.shape)\\n    if i >= 2:\\n        break\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\n",
    "for i, element in enumerate(reshaped_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZP6KKa3CDPf"
   },
   "source": [
    "**Displaying the shapes of the data and labels yielded by the `Dataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.011755Z",
     "iopub.status.busy": "2023-10-21T20:00:13.010733Z",
     "iopub.status.idle": "2023-10-21T20:00:13.014660Z",
     "shell.execute_reply": "2023-10-21T20:00:13.015366Z"
    },
    "id": "1oQxuCKTCDPf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor data_batch, labels_batch in train_dataset:\\n    print(\"data batch shape:\", data_batch.shape)\\n    print(\"labels batch shape:\", labels_batch.shape)\\n    break\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB5vOQlBCDPg"
   },
   "source": [
    "**Fitting the model using a `Dataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.022155Z",
     "iopub.status.busy": "2023-10-21T20:00:13.021089Z",
     "iopub.status.idle": "2023-10-21T20:00:13.026138Z",
     "shell.execute_reply": "2023-10-21T20:00:13.025239Z"
    },
    "id": "948qTTk7CDPg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncallbacks = [\\n    keras.callbacks.ModelCheckpoint(\\n        filepath=\"convnet_from_scratch.keras\",\\n        save_best_only=True,\\n        monitor=\"val_loss\")\\n]\\nhistory = model.fit(\\n    train_dataset,\\n    epochs=30,\\n    validation_data=validation_dataset,\\n    callbacks=callbacks)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAT29S8pCDPg"
   },
   "source": [
    "**Displaying curves of loss and accuracy during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.032842Z",
     "iopub.status.busy": "2023-10-21T20:00:13.031856Z",
     "iopub.status.idle": "2023-10-21T20:00:13.035860Z",
     "shell.execute_reply": "2023-10-21T20:00:13.036679Z"
    },
    "id": "BV339wOHCDPg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\naccuracy = history.history[\"accuracy\"]\\nval_accuracy = history.history[\"val_accuracy\"]\\nloss = history.history[\"loss\"]\\nval_loss = history.history[\"val_loss\"]\\nepochs = range(1, len(accuracy) + 1)\\nplt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\\nplt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\\nplt.title(\"Training and validation accuracy\")\\nplt.legend()\\nplt.figure()\\nplt.plot(epochs, loss, \"bo\", label=\"Training loss\")\\nplt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\\nplt.title(\"Training and validation loss\")\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2biw2rcCDPh"
   },
   "source": [
    "**Evaluating the model on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.042531Z",
     "iopub.status.busy": "2023-10-21T20:00:13.041559Z",
     "iopub.status.idle": "2023-10-21T20:00:13.045362Z",
     "shell.execute_reply": "2023-10-21T20:00:13.046108Z"
    },
    "id": "Kw2HQvKqCDPh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_model = keras.models.load_model(\"convnet_from_scratch.keras\")\\ntest_loss, test_acc = test_model.evaluate(test_dataset)\\nprint(f\"Test accuracy: {test_acc:.3f}\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59JIBMkeCDPh"
   },
   "source": [
    "### Using data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4Mf-qDmCDPi"
   },
   "source": [
    "**Define a data augmentation stage to add to an image model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.052144Z",
     "iopub.status.busy": "2023-10-21T20:00:13.051210Z",
     "iopub.status.idle": "2023-10-21T20:00:13.054766Z",
     "shell.execute_reply": "2023-10-21T20:00:13.055377Z"
    },
    "id": "SbEnboYqCDPi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_augmentation = keras.Sequential(\\n    [\\n        layers.RandomFlip(\"horizontal\"),\\n        layers.RandomRotation(0.1),\\n        layers.RandomZoom(0.2),\\n    ]\\n)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCMayLeOCDPi"
   },
   "source": [
    "**Displaying some randomly augmented training images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.060931Z",
     "iopub.status.busy": "2023-10-21T20:00:13.060042Z",
     "iopub.status.idle": "2023-10-21T20:00:13.063339Z",
     "shell.execute_reply": "2023-10-21T20:00:13.063928Z"
    },
    "id": "A8aj4vANCDPj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(10, 10))\\nfor images, _ in train_dataset.take(1):\\n    for i in range(9):\\n        augmented_images = data_augmentation(images)\\n        ax = plt.subplot(3, 3, i + 1)\\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\\n        plt.axis(\"off\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNziOokECDPj"
   },
   "source": [
    "**Defining a new convnet that includes image augmentation and dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.069105Z",
     "iopub.status.busy": "2023-10-21T20:00:13.068368Z",
     "iopub.status.idle": "2023-10-21T20:00:13.072002Z",
     "shell.execute_reply": "2023-10-21T20:00:13.073109Z"
    },
    "id": "MyWACP8CCDPk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputs = keras.Input(shape=(180, 180, 3))\\nx = data_augmentation(inputs)\\nx = layers.Rescaling(1./255)(x)\\nx = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\nx = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\\nx = layers.Flatten()(x)\\nx = layers.Dropout(0.5)(x)\\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\\nmodel = keras.Model(inputs=inputs, outputs=outputs)\\n\\nmodel.compile(loss=\"binary_crossentropy\",\\n              optimizer=\"rmsprop\",\\n              metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT51jSbLCDPk"
   },
   "source": [
    "**Training the regularized convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.078266Z",
     "iopub.status.busy": "2023-10-21T20:00:13.077461Z",
     "iopub.status.idle": "2023-10-21T20:00:13.081146Z",
     "shell.execute_reply": "2023-10-21T20:00:13.081827Z"
    },
    "id": "fZL5nFXuCDPk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncallbacks = [\\n    keras.callbacks.ModelCheckpoint(\\n        filepath=\"convnet_from_scratch_with_augmentation.keras\",\\n        save_best_only=True,\\n        monitor=\"val_loss\")\\n]\\nhistory = model.fit(\\n    train_dataset,\\n    epochs=100,\\n    validation_data=validation_dataset,\\n    callbacks=callbacks)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07jIY-3yCDPl"
   },
   "source": [
    "**Evaluating the model on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.086920Z",
     "iopub.status.busy": "2023-10-21T20:00:13.086111Z",
     "iopub.status.idle": "2023-10-21T20:00:13.089274Z",
     "shell.execute_reply": "2023-10-21T20:00:13.089848Z"
    },
    "id": "4_WMA5i4CDPl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_model = keras.models.load_model(\\n    \"convnet_from_scratch_with_augmentation.keras\")\\ntest_loss, test_acc = test_model.evaluate(test_dataset)\\nprint(f\"Test accuracy: {test_acc:.3f}\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_model = keras.models.load_model(\n",
    "    \"convnet_from_scratch_with_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bFyFXezCDPl"
   },
   "source": [
    "## Leveraging a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDxQM0teCDPm"
   },
   "source": [
    "### Feature extraction with a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZTotrdxCDPn"
   },
   "source": [
    "**Instantiating the VGG16 convolutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:13.098568Z",
     "iopub.status.busy": "2023-10-21T20:00:13.097818Z",
     "iopub.status.idle": "2023-10-21T20:00:14.061015Z",
     "shell.execute_reply": "2023-10-21T20:00:14.059669Z"
    },
    "id": "GBR2XOJNCDPn"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras # import keras\n",
    "from tensorflow.keras import layers \n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:14.069686Z",
     "iopub.status.busy": "2023-10-21T20:00:14.066005Z",
     "iopub.status.idle": "2023-10-21T20:00:14.082316Z",
     "shell.execute_reply": "2023-10-21T20:00:14.082759Z"
    },
    "id": "Q3NijRLeCDPn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 180, 180, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 180, 180, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 90, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 90, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 45, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opOCS5pJCDPn",
    "tags": []
   },
   "source": [
    "#### Fast feature extraction without data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMW9QZSrCDPo"
   },
   "source": [
    "**Extracting the VGG16 features and corresponding labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:14.093087Z",
     "iopub.status.busy": "2023-10-21T20:00:14.091224Z",
     "iopub.status.idle": "2023-10-21T20:00:34.985233Z",
     "shell.execute_reply": "2023-10-21T20:00:34.983548Z"
    },
    "id": "6TwjB6rKCDPo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
    "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels =  get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:34.992388Z",
     "iopub.status.busy": "2023-10-21T20:00:34.990907Z",
     "iopub.status.idle": "2023-10-21T20:00:34.996141Z",
     "shell.execute_reply": "2023-10-21T20:00:34.997240Z"
    },
    "id": "ZshtzB-ZCDPo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5, 5, 512)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqTBM2rBCDPo"
   },
   "source": [
    "**Defining and training the densely connected classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:35.007625Z",
     "iopub.status.busy": "2023-10-21T20:00:35.006274Z",
     "iopub.status.idle": "2023-10-21T20:00:39.747661Z",
     "shell.execute_reply": "2023-10-21T20:00:39.748396Z"
    },
    "id": "aMU01CJvCDPo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 6ms/step - loss: 13.5073 - accuracy: 0.9210 - val_loss: 4.7467 - val_accuracy: 0.9660\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 3.0386 - accuracy: 0.9770 - val_loss: 12.0533 - val_accuracy: 0.9430\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1036 - accuracy: 0.9850 - val_loss: 3.2843 - val_accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.9179 - accuracy: 0.9875 - val_loss: 7.3282 - val_accuracy: 0.9700\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9677 - accuracy: 0.9900 - val_loss: 6.0118 - val_accuracy: 0.9650\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2342 - accuracy: 0.9935 - val_loss: 6.0537 - val_accuracy: 0.9710\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9975 - val_loss: 6.1084 - val_accuracy: 0.9700\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.9970 - val_loss: 5.7784 - val_accuracy: 0.9710\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9985 - val_loss: 8.9953 - val_accuracy: 0.9640\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.9970 - val_loss: 5.5047 - val_accuracy: 0.9730\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 0.9965 - val_loss: 5.4949 - val_accuracy: 0.9760\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.9975 - val_loss: 5.0313 - val_accuracy: 0.9740\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.9965 - val_loss: 6.3703 - val_accuracy: 0.9710\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.9975 - val_loss: 5.6572 - val_accuracy: 0.9760\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9990 - val_loss: 5.7342 - val_accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9975 - val_loss: 5.3191 - val_accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9965 - val_loss: 5.0407 - val_accuracy: 0.9760\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9990 - val_loss: 5.0738 - val_accuracy: 0.9770\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 5.6584 - val_accuracy: 0.9770\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.5128e-17 - accuracy: 1.0000 - val_loss: 5.6584 - val_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "      filepath=\"feature_extraction.keras\",\n",
    "      save_best_only=True,\n",
    "      monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rni2lbdnCDPp"
   },
   "source": [
    "**Plotting the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:39.756307Z",
     "iopub.status.busy": "2023-10-21T20:00:39.755773Z",
     "iopub.status.idle": "2023-10-21T20:00:42.188005Z",
     "shell.execute_reply": "2023-10-21T20:00:42.189478Z"
    },
    "id": "liYT21N8CDPp"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esS3CubxCDPp"
   },
   "source": [
    "#### Feature extraction together with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM8OUkXuCDPp"
   },
   "source": [
    "**Instantiating and freezing the VGG16 convolutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:42.206146Z",
     "iopub.status.busy": "2023-10-21T20:00:42.204024Z",
     "iopub.status.idle": "2023-10-21T20:00:42.595550Z",
     "shell.execute_reply": "2023-10-21T20:00:42.594312Z"
    },
    "id": "Ir6Ke9NGCDPp"
   },
   "outputs": [],
   "source": [
    "conv_base  = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False)\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ9xp-jBCDPp"
   },
   "source": [
    "**Printing the list of trainable weights before and after freezing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:42.602853Z",
     "iopub.status.busy": "2023-10-21T20:00:42.601569Z",
     "iopub.status.idle": "2023-10-21T20:00:42.607068Z",
     "shell.execute_reply": "2023-10-21T20:00:42.605822Z"
    },
    "id": "VIm7-3xICDPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 26\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "print(\"This is the number of trainable weights \"\n",
    "      \"before freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:42.613322Z",
     "iopub.status.busy": "2023-10-21T20:00:42.612130Z",
     "iopub.status.idle": "2023-10-21T20:00:42.617816Z",
     "shell.execute_reply": "2023-10-21T20:00:42.616636Z"
    },
    "id": "zWQJW7DUCDPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 0\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = False\n",
    "print(\"This is the number of trainable weights \"\n",
    "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jO3DwerCDPq"
   },
   "source": [
    "**Adding a data augmentation stage and a classifier to the convolutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:42.625689Z",
     "iopub.status.busy": "2023-10-21T20:00:42.622043Z",
     "iopub.status.idle": "2023-10-21T20:00:42.906468Z",
     "shell.execute_reply": "2023-10-21T20:00:42.907784Z"
    },
    "id": "roDIyEA3CDPq"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:00:42.915560Z",
     "iopub.status.busy": "2023-10-21T20:00:42.913948Z",
     "iopub.status.idle": "2023-10-21T20:03:39.524776Z",
     "shell.execute_reply": "2023-10-21T20:03:39.525756Z"
    },
    "id": "EQtMjU26CDPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 56ms/step - loss: 21.2061 - accuracy: 0.8910 - val_loss: 22.9828 - val_accuracy: 0.8940\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 7.0033 - accuracy: 0.9445 - val_loss: 5.7581 - val_accuracy: 0.9620\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 6.5587 - accuracy: 0.9570 - val_loss: 5.6807 - val_accuracy: 0.9590\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 4.4935 - accuracy: 0.9605 - val_loss: 6.0700 - val_accuracy: 0.9640\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 3.2817 - accuracy: 0.9675 - val_loss: 6.1735 - val_accuracy: 0.9650\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 5.4043 - accuracy: 0.9590 - val_loss: 7.8655 - val_accuracy: 0.9640\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 4.8845 - accuracy: 0.9620 - val_loss: 2.8868 - val_accuracy: 0.9760\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 2.2545 - accuracy: 0.9765 - val_loss: 5.1264 - val_accuracy: 0.9700\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 2.3987 - accuracy: 0.9770 - val_loss: 4.8956 - val_accuracy: 0.9740\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 2.7642 - accuracy: 0.9730 - val_loss: 4.4262 - val_accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 2.7902 - accuracy: 0.9755 - val_loss: 3.1060 - val_accuracy: 0.9770\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 2.5042 - accuracy: 0.9755 - val_loss: 4.9537 - val_accuracy: 0.9680\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.4807 - accuracy: 0.9795 - val_loss: 3.4375 - val_accuracy: 0.9790\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.5025 - accuracy: 0.9840 - val_loss: 3.9441 - val_accuracy: 0.9740\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.9034 - accuracy: 0.9805 - val_loss: 3.6990 - val_accuracy: 0.9730\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 2.0529 - accuracy: 0.9770 - val_loss: 4.0766 - val_accuracy: 0.9780\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.4646 - accuracy: 0.9790 - val_loss: 3.3099 - val_accuracy: 0.9770\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.4809 - accuracy: 0.9820 - val_loss: 3.2118 - val_accuracy: 0.9720\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.1507 - accuracy: 0.9815 - val_loss: 2.6941 - val_accuracy: 0.9750\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 1.6299 - accuracy: 0.9805 - val_loss: 2.7439 - val_accuracy: 0.9760\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 1.1083 - accuracy: 0.9845 - val_loss: 3.9618 - val_accuracy: 0.9790\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.3424 - accuracy: 0.9835 - val_loss: 3.0976 - val_accuracy: 0.9810\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.3167 - accuracy: 0.9795 - val_loss: 3.8232 - val_accuracy: 0.9720\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 1.3782 - accuracy: 0.9810 - val_loss: 2.3537 - val_accuracy: 0.9780\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.9867 - accuracy: 0.9845 - val_loss: 2.9392 - val_accuracy: 0.9770\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.9766 - accuracy: 0.9825 - val_loss: 2.4336 - val_accuracy: 0.9780\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.0308 - accuracy: 0.9830 - val_loss: 3.6002 - val_accuracy: 0.9720\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.6114 - accuracy: 0.9850 - val_loss: 2.4190 - val_accuracy: 0.9810\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.7387 - accuracy: 0.9855 - val_loss: 4.1295 - val_accuracy: 0.9660\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.5670 - accuracy: 0.9845 - val_loss: 3.4808 - val_accuracy: 0.9740\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.7438 - accuracy: 0.9855 - val_loss: 2.7265 - val_accuracy: 0.9750\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.6358 - accuracy: 0.9880 - val_loss: 4.9777 - val_accuracy: 0.9630\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.0329 - accuracy: 0.9845 - val_loss: 2.0601 - val_accuracy: 0.9770\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.5896 - accuracy: 0.9895 - val_loss: 2.1925 - val_accuracy: 0.9800\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.9808 - accuracy: 0.9855 - val_loss: 2.6108 - val_accuracy: 0.9790\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 4s 53ms/step - loss: 0.8450 - accuracy: 0.9850 - val_loss: 2.7040 - val_accuracy: 0.9710\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.5562 - accuracy: 0.9875 - val_loss: 2.3025 - val_accuracy: 0.9730\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.2197 - accuracy: 0.9820 - val_loss: 2.5752 - val_accuracy: 0.9760\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.6530 - accuracy: 0.9890 - val_loss: 3.0409 - val_accuracy: 0.9690\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.3301 - accuracy: 0.9940 - val_loss: 2.8597 - val_accuracy: 0.9800\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.5592 - accuracy: 0.9895 - val_loss: 2.3041 - val_accuracy: 0.9750\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.5874 - accuracy: 0.9920 - val_loss: 2.4542 - val_accuracy: 0.9760\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.3692 - accuracy: 0.9905 - val_loss: 2.3337 - val_accuracy: 0.9780\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.9109 - accuracy: 0.9860 - val_loss: 2.7692 - val_accuracy: 0.9780\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.8140 - accuracy: 0.9860 - val_loss: 2.4054 - val_accuracy: 0.9750\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.7053 - accuracy: 0.9885 - val_loss: 2.5727 - val_accuracy: 0.9790\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.6289 - accuracy: 0.9865 - val_loss: 2.2830 - val_accuracy: 0.9760\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.5192 - accuracy: 0.9885 - val_loss: 2.3128 - val_accuracy: 0.9780\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.5046 - accuracy: 0.9905 - val_loss: 2.6822 - val_accuracy: 0.9770\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.8204 - accuracy: 0.9860 - val_loss: 2.0805 - val_accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc7jIguOCDPq"
   },
   "source": [
    "**Evaluating the model on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:03:39.533440Z",
     "iopub.status.busy": "2023-10-21T20:03:39.530418Z",
     "iopub.status.idle": "2023-10-21T20:03:41.841379Z",
     "shell.execute_reply": "2023-10-21T20:03:41.840362Z"
    },
    "id": "vE3IA6DeCDPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 32ms/step - loss: 2.4537 - accuracy: 0.9770\n",
      "Test accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\n",
    "    \"feature_extraction_with_data_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwoaUGYDCDPr"
   },
   "source": [
    "### Fine-tuning a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:03:41.848941Z",
     "iopub.status.busy": "2023-10-21T20:03:41.847834Z",
     "iopub.status.idle": "2023-10-21T20:03:41.866098Z",
     "shell.execute_reply": "2023-10-21T20:03:41.867060Z"
    },
    "id": "ea0oRsFNCDPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0-rO_h4CDPr"
   },
   "source": [
    "**Freezing all layers until the fourth from the last**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:03:41.876330Z",
     "iopub.status.busy": "2023-10-21T20:03:41.875230Z",
     "iopub.status.idle": "2023-10-21T20:03:41.878379Z",
     "shell.execute_reply": "2023-10-21T20:03:41.879231Z"
    },
    "id": "Imk9UeGUCDPr"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDlYA6aBCDPr"
   },
   "source": [
    "**Fine-tuning the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:03:41.888762Z",
     "iopub.status.busy": "2023-10-21T20:03:41.887689Z",
     "iopub.status.idle": "2023-10-21T20:05:37.678577Z",
     "shell.execute_reply": "2023-10-21T20:05:37.679738Z"
    },
    "id": "biJcRYHzCDPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 5s 61ms/step - loss: 0.3013 - accuracy: 0.9920 - val_loss: 2.3283 - val_accuracy: 0.9720\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.4117 - accuracy: 0.9850 - val_loss: 2.0034 - val_accuracy: 0.9790\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.4557 - accuracy: 0.9890 - val_loss: 2.1317 - val_accuracy: 0.9780\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.3864 - accuracy: 0.9875 - val_loss: 2.2103 - val_accuracy: 0.9800\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.2877 - accuracy: 0.9920 - val_loss: 2.3774 - val_accuracy: 0.9760\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.2910 - accuracy: 0.9890 - val_loss: 2.4382 - val_accuracy: 0.9740\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1776 - accuracy: 0.9930 - val_loss: 2.0192 - val_accuracy: 0.9780\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.3179 - accuracy: 0.9915 - val_loss: 2.1185 - val_accuracy: 0.9750\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2422 - accuracy: 0.9930 - val_loss: 1.8964 - val_accuracy: 0.9770\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2623 - accuracy: 0.9940 - val_loss: 1.5055 - val_accuracy: 0.9820\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2996 - accuracy: 0.9920 - val_loss: 1.2986 - val_accuracy: 0.9820\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0817 - accuracy: 0.9975 - val_loss: 1.7039 - val_accuracy: 0.9800\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2091 - accuracy: 0.9940 - val_loss: 1.7767 - val_accuracy: 0.9820\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2408 - accuracy: 0.9940 - val_loss: 1.6753 - val_accuracy: 0.9810\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2389 - accuracy: 0.9950 - val_loss: 1.4084 - val_accuracy: 0.9800\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1064 - accuracy: 0.9955 - val_loss: 1.6390 - val_accuracy: 0.9790\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0449 - accuracy: 0.9990 - val_loss: 1.6157 - val_accuracy: 0.9790\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1464 - accuracy: 0.9930 - val_loss: 1.7780 - val_accuracy: 0.9770\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.2795 - accuracy: 0.9955 - val_loss: 1.5480 - val_accuracy: 0.9780\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0916 - accuracy: 0.9970 - val_loss: 1.7212 - val_accuracy: 0.9760\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.0743 - accuracy: 0.9965 - val_loss: 1.1029 - val_accuracy: 0.9800\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1037 - accuracy: 0.9960 - val_loss: 1.8676 - val_accuracy: 0.9760\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.1488 - accuracy: 0.9940 - val_loss: 1.5035 - val_accuracy: 0.9810\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0420 - accuracy: 0.9970 - val_loss: 1.4502 - val_accuracy: 0.9810\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0781 - accuracy: 0.9965 - val_loss: 1.5331 - val_accuracy: 0.9810\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.1049 - accuracy: 0.9955 - val_loss: 1.3614 - val_accuracy: 0.9800\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0205 - accuracy: 0.9985 - val_loss: 1.2473 - val_accuracy: 0.9820\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1799 - accuracy: 0.9940 - val_loss: 1.7278 - val_accuracy: 0.9790\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0545 - accuracy: 0.9980 - val_loss: 1.5502 - val_accuracy: 0.9820\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.0587 - accuracy: 0.9950 - val_loss: 2.0134 - val_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"fine_tuning.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T20:05:37.688199Z",
     "iopub.status.busy": "2023-10-21T20:05:37.686795Z",
     "iopub.status.idle": "2023-10-21T20:05:40.534204Z",
     "shell.execute_reply": "2023-10-21T20:05:40.535164Z"
    },
    "id": "-5WMjJDBCDPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 33ms/step - loss: 1.5191 - accuracy: 0.9810\n",
      "Test accuracy: 0.981\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"fine_tuning.keras\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_QxUVQNCDPs",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter08_intro-to-dl-for-computer-vision.ipynb",
     "timestamp": 1697604276120
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
